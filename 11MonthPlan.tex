\section{Project summary / abstract}

In the past few decades, much research has been done on digital sound synthesis. Using a physical model (PM) of a musical instrument, rather than for example using sampling synthesis for creating sound, makes the playability of the digital instrument very flexible. In other words, the now-virtual instrument can easily adapt to changes in performance and playing style. Many PMs already exist and can output high quality sound which is sometimes indistinguishable from the real instrument.

“Why not just use the real instrument?” you might ask. Physical modelling makes it possible to extend traditional instruments in ways that would be impossible in the real world. Changing the shape, size or material of the instrument over time potentially results in interesting sounds and could even extend the possibilities for expression for the musician. 

Going a step further, different components of different instruments can be linked together to create hybrid instruments. Most instruments can be divided into an exciter and a resonator component. Virtually connecting, for example, the mouthpiece of a trumpet to the string of a guitar could potentially lead to interesting sounds.

There are various techniques to implement physical models, where there is a tradeoff between accuracy and speed making high-quality physical modelling very computationally expensive. Only recently have we been able to run existing highly accurate PMs in real-time, making them playable for performers and musicians. The PhD project will focus on implementing existing PMs using techniques focusing on accuracy in real-time.

As the implemented models will be playable in real-time, I will investigate the use of different controllers, such as the Sensel Morph \cite{Sensel2019}. and the Haply \cite{Haply2019}.

The outcome of this project will be to push the state of the art in real-time accurate physical models and explore the possibilities that come with this, such as changing physically fixed parameters in real-time and combining components of different instruments to allow for novel interactions and create sounds never heard before. The output sound is expected to still be natural as the algorithm is based on physics.

\section{The scientific content of the PhD project}

\subsection{Background}
Physical modelling, along with sampling synthesis (also known as wavetable synthesis \cite{Smith2010a}) and spectral modelling, is a technique to synthesise sound. According to many, physical modelling is the best technique to realistically and naturally simulate real-world musical instruments \cite{Valimaki2006, Smith2010b, Bilbao2009}. As this technique simulates the instrument based on its physics rather than using pre-recorded samples, it is more flexible to player-interaction and thus more realistic when synthesising sound in performance. Although physical models (PMs) could potentially sound indistinguishable from the instrument that they are simulating, it has been impossible - until recently - to make high-quality — which I define as non-linear and based on finite-difference schemes (FDSs) — PMs ‘playable’ in real time \cite{Smith2010a}. With the computational power we currently possess, we can run the PMs in real-time and make them available for musicians in latency-less applications.

///////
Physical modelling is also at the centre of a completely new field: Hybrid Acoustic-Virtual Instruments (HAVIs). Using the fact that the sound creation in a traditional musical instrument can be divided in an exciter and a resonator component, HAVIs take one of these components and bring this back to the real world. Not only does this create sonically interesting results, it also relieves the PM of many computations.
///////

Even though there are already existing real-time PMs (see Section b), to my opinion, they do not make use of the full potential of using physical modelling for sound synthesis. PMs make it possible for parameters like shape, size, material properties, etc. to be changed, which is physically impossible or very hard to do. This can result in unique sounds that can only be created using PMs.

\subsection{State-of-the-art}
This section will give a brief introduction on the state of the art on physical models, real-time implementation of these, modular environments for sound synthesis and instrument extension.

\subsubsection*{Physical Modelling}
The physics of musical instruments can be well described by partial differential equations (PDEs) (see \cite{Bilbao2009} among many others). Many of these equations and other knowledge currently available on the physics of musical instruments have been collected by N. H. Fletcher and T. D. Rossing in \cite{Fletcher1998}. In the past decades, much research (a lot based on the aforementioned book) has been done on implementing these PDEs to model and simulate different musical instruments. Great overviews of implementation techniques are given by, for example, Vesa Välimäki et al. in \cite{Valimaki2006} and Julius O. Smith in \cite{Smith2010a, Smith2010b}. Some techniques that are described in this literature can be found below:

Modal Synthesis decomposes a system into a series of uncoupled ‘modes of vibration’. \textbf{FIRST DEVISED BY...} Compared to finite-difference schemes (see below) this technique is extremely computationally efficient, especially in higher dimensional systems such as plates (2D) or rooms (3D) \textbf{THIS IS CORRECT RIGHT?}.It is especially effective when used to describe a linear system \cite{Bilbao2018} with a small number of long-resonating modes \cite{Smith2010a}. When used to describe non-linear systems, however, the modes become `coupled’ and the system will quickly become more computationally expensive. 

Finite-Difference Schemes (FDS) aim to solve PDEs by approximating them with difference equations, discretising a continuous system into grid-points in space and time. Stefan Bilbao extensively describes this method in \cite{Bilbao2009, Bilbao2018}. Although very computationally expensive, this technique can most accurately resemble any system, whether it is linear or non-linear, time-invariant or time-variant.

Digital Waveguide Modelling (or Digital Waveguides (DWG)) is a modelling technique that discretises wave propagation and scattering. It is mostly used for one-dimensional systems, such as strings and acoustic tubes and decomposes their system into travelling wave components. This technique has also been used in higher-dimensional systems, but is superior in efficiency when used in the one-dimensional case \cite{Valimaki2006}. Some authors have combined DWGs with FDS (such as in \cite{Erkut2002, Maestre2014}) to accurately model non-linear behaviour while maintaining high-speed implementation.

\subsubsection*{Real-time implementation}
Even though physical modelling has been a popular research field in the past few decades, relatively little research has been done on making the models work in real-time, i.e. `playable’ \cite{Mehes2016}. Several virtual string instruments and different electric pianos have been made real-time by F. Pfeifle and R. Bader \cite{Pfeifle2012, Pfeifle2015, Pfeifle2017}. They used field programmable gate arrays (FPGA) for implementing models based on FDS. Furthermore, Roland’s V-series use COSM (Composite Object Sound Modelling) technology \cite{Bybee2019} that implement real-time physical models in hardware instruments.

In the NESS project \cite{NESS2016}, Stefan Bilbao and his team focused on implementing systems based on FDS (or Finite Difference Time-Domain methods) in real time. In one of the papers on this \cite{Webb2015} they present a real time physically modelled implementation of strings/bars and plates in a modular environment. Using C combined with AVX and multithreading they are able to make a system that can run a model of a plate with approximately 7000 grid points virtually connected to 10 strings run on a 4-core processor with a base clock rate of 3.1GHz. Their paper will be a good starting point for creating real-time models for musical instruments rather than ‘simple’ 1D and 2D models.
/////
Hybrid Acoustic-Virtual Instruments
I define a HAVI as an instrument with at least one acoustic (physical) and one virtual (physically modelled) component. It uses the decomposition of a musical instrument in an exciter and a resonator (as first presented in \cite{Borin1989}) and virtualises one component while the other stays in the physical world. Considering the fact that real-time PMs have not been in existence for long, it can be seen why research on these type of instruments is still in its infancy. Below, the two general cases for an instrument being classified as a HAVI are presented:

Physical Exciter - Virtual Resonator
Typically the exciter is taken as being the physical component. In his projects, such as the BladeAxe and PlateAxe \cite{Michon2016}, Romain Michon uses a physical exciter to control a physical model of strings or percussive instruments. His models are all using modal synthesis as an implementation technique. The same is done by Sandor Mehes and Maarten van Walstijn in \cite{Mehes2016, Mehes2017, Walstijn2017} where the authors use a physical string to excite a modal-synthesis-based virtual plate.

In the context of HAVIs, to the best of my knowledge, there has been no record of anyone using FDS allowing for non-linear PMs. This is most probably due to its low computational efficiency. 

Virtual Exciter - Physical Resonator
There are also examples of actuated physical resonators such as the EMdrum \cite{Rector2014} and the Bistable Resonator Cymbal \cite{Piepenbrink2015}. These do not, however, use physically modelled exciters as their input sound. In this project, I would like to investigate the possibility of using a physical resonator (such as a guitar body) to act like a real-world convolution and make a PM sound more natural.
/////

Modular Environments for Sound Synthesis
As will be described in the next section, the goal of the project is to create a modular environment consisting of different physical/virtual exciters and resonators. An existing modular environment for sound synthesis is the Synth Kit by littleBits \cite{littleBits2019} where the different modules are oscillators, filters, sequencers, etc., essentially making it a modular synthesiser where the components can physically be moved around and connected. Another example is MuX by Decochon \cite{MuX2019}, a modular synthesiser that a user can build and control in virtual reality. Both of these examples present an alternative way to control a modular synthesiser and are not based on physical models.

Extending Physical Models (from physically static to virtually dynamic)
There is a lot of potential when using physical modelling to make physically fixed parameters virtually dynamic. The main reasons to do this is to 
create sonically interesting results and,
extend the possibilities and (potentially) enhancing expressivity for the musician.
An example of existing dynamic physical models is Michon’s BladeAxe, which allows the user to alter the string length in real-time with the only control being the speed of an LFO. In \cite{Gelineck2005}, the authors present a flute of which the length can be changed in real-time using a foot-pedal. In \cite{Willemsen2017}, I presented extensions to a plate reverb where the length and width of the plate and the microphone positions could be altered in real-time. In the PhD project extensions like these will be  further explored.

\subsection{Project objectives}
\subsection{Key methods}
\subsection{Significance and outcome}

\section{Work and publication plans}
\subsection{Work and Time Plans}
\subsection{Outline of thesis}
\subsection{Tentative publication list}

\section{Supervisor/student co-operation agreements}

\section{Plan for PhD Courses (both general and project related courses)}

\section{Plan for fulfilment of knowledge dissemination}

\section{Agreements on immaterial rights to patents}

\section{External co-operation}

\section{Financing budget}